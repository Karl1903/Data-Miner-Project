{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining Versuch Document Classification\n",
    "* Autor: Prof. Dr. Johannes Maucher\n",
    "* Datum: 06.11.2015\n",
    "\n",
    "[Übersicht Ipython Notebooks im Data Mining Praktikum](Data Mining Praktikum.ipynb)\n",
    "\n",
    "# Einführung\n",
    "## Lernziele:\n",
    "In diesem Versuch sollen Kenntnisse in folgenden Themen vermittelt werden:\n",
    "\n",
    "* Dokumentklassifikation: Klassifikation von Dokumenten, insbesondere Emails und RSS Feed\n",
    "* Naive Bayes Classifier: Weit verbreitete Klassifikationsmethode, welche unter bestimmten Randbedingungen sehr gut skaliert.\n",
    "\n",
    "\n",
    "## Theorie zur Vorbereitung\n",
    "### Parametrische Klassifikation und Naive Bayes Methode\n",
    "Klassifikatoren müssen zu einer gegebenen Eingabe $\\underline{x}$ die zugehörige Klasse $C_i$ bestimmen. Mithilfe der Wahrscheinlichkeitstheorie kann diese Aufgabe wie folgt beschrieben werden: Bestimme für alle möglichen Klassen $C_i$ die bedingte Wahrscheinlichkeit $P(C_i | \\underline{x})$, also die Wahrscheinlichkeit, dass die gegebene Eingabe $\\underline{x}$ in Klasse $C_i$ fällt. Wähle dann die Klasse aus, für welche diese Wahrscheinlichkeit maximal ist.\n",
    "\n",
    "Die Entscheidungsregeln von Klassifikatoren können mit Methoden des \"\"überwachten Lernens\"\" aus Trainingsdaten ermittelt werden. Im Fall des **parametrischen Lernens** kann aus den Trainingsdaten die sogenannte **Likelihood-Funktion** $p(\\underline{x} \\mid C_i)$ bestimmt werden. _Anmerkung:_ Allgemein werden mit $p(...)$ kontinuierliche Wahrscheinlichkeitsfunktionen und mit $P(...)$ diskrete Wahrscheinlichkeitswerte bezeichnet. \n",
    "\n",
    "Mithilfe der **Bayes-Formel**\n",
    "$$\n",
    "P(C_i \\mid \\underline{x}) = \\frac{p(\\underline{x} \\mid C_i) \\cdot P(C_i)}{p(\\underline{x})}\n",
    "$$\n",
    "\n",
    "kann aus der Likelihood die **a-posteriori-Wahrscheinlichkeit $P(C_i \\mid \\underline{x})$** berechnet werden. Darin wird $P(C_i)$ die **a-priori-Wahrscheinlichkeit** und $p(\\underline{x})$ die **Evidenz** genannt. Die a-priori-Wahrscheinlichkeit kann ebenfalls aus den Trainingsdaten ermittelt werden. Die Evidenz ist für die Klassifikationsentscheidung nicht relevant, da sie für alle Klassen $C_i$ gleich groß ist.\n",
    "\n",
    "Die Berechnung der Likelihood-Funktion $p(\\underline{x} \\mid C_i)$ ist dann sehr aufwendig, wenn $\\underline{x}=(x_1,x_2,\\ldots,x_Z)$ ein Vektor von voneinander abhängigen Variablen $x_i$ ist. Bei der **Naive Bayes Classification** wird jedoch von der vereinfachenden Annahme ausgegangen, dass die Eingabevariabeln $x_i$ voneinander unabhängig sind. Dann vereinfacht sich die bedingte Verbundwahrscheinlichkeits-Funktion $p(x_1,x_2,\\ldots,x_Z \\mid C_i)$ zu:\n",
    "\n",
    "$$\n",
    "p(x_1,x_2,\\ldots,x_Z \\mid C_i)=\\prod\\limits_{j=1}^Z p(x_j | C_i)\n",
    "$$\n",
    "\n",
    "### Anwendung der Naive Bayes Methode in der Dokumentklassifikation\n",
    "Auf der rechten Seite der vorigen Gleichung stehen nur noch von den jeweils anderen Variablen unabhängige bedingte Wahrscheinlichkeiten. Im Fall der Dokumentklassifikation sind die einzelnen Worte die Variablen, d.h. ein Ausdruck der Form $P(x_j | C_i)$ gibt an mit welcher Wahrscheinlichkeit ein Wort $x_j=w$ in einem Dokument der Klasse $C_i$ vorkommt. \n",
    "Die Menge aller Variablen $\\left\\{x_1,x_2,\\ldots,x_Z \\right\\}$ ist dann die Menge aller Wörter im Dokument. Damit gibt die linke Seite in der oben gegebenen Gleichung die _Wahrscheinlichkeit, dass die Wörter $\\left\\{x_1,x_2,\\ldots,x_Z \\right\\}$ in einem Dokument der Klasse $C_i$ vorkommen_ an.\n",
    "\n",
    "Für jedes Wort _w_ wird aus den Trainingsdaten die Wahrscheinlichkeit $P(w|G)$, mit der das Wort in Dokumenten der Kategorie _Good_ und die Wahrscheinlichkeit $P(w|B)$ mit der das Wort in Dokumenten der Kategorie _Bad_ auftaucht ermittelt. Trainingsdokumente werden in der Form\n",
    "\n",
    "$$\n",
    "tD=(String,Category)\n",
    "$$\n",
    "eingegeben. \n",
    "\n",
    "Wenn \n",
    "\n",
    "* mit der Variable $fc(w,cat)$ die Anzahl der Trainingsdokumente in Kategorie $cat$ in denen das Wort $w$ enthalten ist\n",
    "* mit der Variable $cc(cat)$ die Anzahl der Trainingsdokumente in Kategorie $cat$ \n",
    "\n",
    "gezählt wird, dann ist \n",
    "\n",
    "$$\n",
    "P(w|G)=\\frac{fc(w,G)}{cc(G)} \\quad \\quad P(w|B)=\\frac{fc(w,B)}{cc(B)}.\n",
    "$$\n",
    "\n",
    "Wird nun nach der Eingabe von $L$ Trainingsdokumenten ein neu zu klassifizierendes Dokument $D$ eingegeben und sei $W(D)$ die Menge aller Wörter in $D$, dann berechnen sich unter der Annahme, dass die Worte in $W(D)$ voneinander unabhängig sind (naive Bayes Annahme) die a-posteriori Wahrscheinlichkeiten zu:\n",
    "\n",
    "$$\n",
    "P(G|D)=\\frac{\\left( \\prod\\limits_{w \\in W(D)} P(w | G) \\right) \\cdot P(G)}{p(D)}\n",
    "$$\n",
    "und\n",
    "$$\n",
    "P(B|D)=\\frac{\\left( \\prod\\limits_{w \\in W(D)} P(w | B) \\right) \\cdot P(B)}{p(D)}.\n",
    "$$\n",
    "\n",
    "Die hierfür notwendigen a-priori-Wahrscheinlichkeiten berechnen sich zu \n",
    "\n",
    "$$\n",
    "P(G)=\\frac{cc(G)}{L}\n",
    "$$\n",
    "und\n",
    "$$\n",
    "P(B)=\\frac{cc(B)}{L}\n",
    "$$\n",
    "\n",
    "Die Evidenz $p(D)$ beeinflusst die Entscheidung nicht und kann deshalb ignoriert werden.\n",
    "\n",
    "\n",
    "## Vor dem Versuch zu klärende Fragen\n",
    "\n",
    "\n",
    "1. Wie wird ein Naive Bayes Classifier trainiert? Was muss beim Training für die spätere Klassifikation abgespeichert werden?\n",
    "2. Wie teilt ein Naiver Bayes Classifier ein neues Dokument ein?\n",
    "3. Welche naive Annahme liegt dem Bayes Classifier zugrunde? Ist diese Annahme im Fall der Dokumentklassifikation tatsächlich gegeben?\n",
    "4. Betrachten Sie die Formeln für die Berechnung von $P(G|D)$ und $P(B|D)$. Welches Problem stellt sich ein, wenn in der Menge $W(D)$ ein Wort vorkommt, das nicht in den Trainingsdaten der Kategorie $G$ vorkommt und ein anderes Wort aus $W(D)$ nicht in den Trainingsdaten der Kategorie $B$ enthalten ist? Wie könnte dieses Problem gelöst werden? \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Überlegungen/Recherche\n",
    "\n",
    "Parameterisierte Klassifikation und Naive Bayes\n",
    "\n",
    "Bayes Formel: a posteriori Wahrscheinlichkeit aus likelyhood berechnen. \n",
    "Likelyhood funktion ist bei voneinander abhängigen Variablen sehr aufwändig. Naive Bayes Classification wird davon ausgegangen dass variablen unabhängig sind. \n",
    "P(w∣G)=cc(G)fc(w,G)P(w∣B)=cc(B)fc(w,B).\n",
    "\n",
    "P(A|B) = P(B|A)* P(A)/P(B)\n",
    "\n",
    "### Aufgaben \n",
    "\n",
    "1. Für jedes Wort aus den Trainingsdaten wird die Wahrscheinlichkeit ermittelt: P(w∣G), also die Wahrscheinlichkeit, dass in einer guten Klasse ein Wort w vorkommt, sowie dasselbe für die schlechte Kategorie. Beim einlernen beschreibt fc(w,cat) die Anzahl der Trainingsdokumente in Kateogrie cat in denen das Wort w enthalten ist, also zb in 20 guten Dokumenten ist das Wort „authentification“ enthalten. \n",
    "Desweiteren beschreibt cc(cat) die Anzahl der Trainingsdokumente in Cat, also zb 50 gute Dokumente insgesamt\n",
    "Daraus fogt, dass P(w|G) fc/cc ist (einfache Wahrscheinlichkeitsrechnung).\n",
    "Für die späteren Aufgaben wird P(w|G) und P(w|B) benötigt.\n",
    "\n",
    "2. naive bayes klaffikation ist ein Verfahren dass auf dem Bayesschen Gesetz basiert: https://www.analyticsvidhya.com/wp-content/uploads/2015/09/Bayes_rule-300x172.png\n",
    "Es wird angenommen, dass alle Wörter in dem Dokument voneinander unabhängig sind\n",
    "Die Wahrscheinlichkeit, dass das Dokument Gut ist, wird berechnet, aus der Wahrscheinlichkeit, dass die jeweiligen Wörter in gutem Dokument auftauchen (wird aufsummiert für alle Wörter) und mit der Wahrscheinlichkeit multipliziert, dass ein Dokument gut ist (P(G)). Evidenz kann ignoriert werden, bzw als 1 betrachtet werden.\n",
    "\n",
    "3. Es wird angenommen, dass alle Wörter in dem Dokument voneinander unabhängig sind. \n",
    "Dies ist nicht gegeben, aber der naive Bayes algorithmus kann aufgrund der Menge der Wörter und der Menge der Daten trotzdem performanter sein als viele konkurrierenden Algorithmen. Deshalb werden die Abhängigkeiten rausreduziert. \n",
    "\n",
    "4. Wenn ein Wort nur in einer Kategorie auftritt, beispielsweise Good, dann beträgt P(w|B)=0\n",
    "Mit der Formel zu der Klassifizierung ist dies sehr problematisch, da dort das Produkt verwendet wird. Das Dokument würde aufgrund dieses einen Wortes also nicht zu der entsprechende Klasse klassifiziert werden können. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Durchführung\n",
    "## Feature Extraction/ -Selection\n",
    "\n",
    "**Aufgabe:**\n",
    "Implementieren Sie eine Funktion _getwords(doc)_, der ein beliebiges Dokument in Form einer String-Variablen übergeben wird. In der Funktion soll der String in seine Wörter zerlegt und jedes Wort in _lowercase_ transformiert werden. Wörter, die weniger als eine untere Grenze von Zeichen (z.B. 3) oder mehr als eine obere Grenze von Zeichen (z.B. 20) enthalten, sollen ignoriert werden. Die Funktion soll ein dictionary zurückgeben, dessen _Keys_ die Wörter sind. Die _Values_ sollen für jedes Wort zunächst auf $1$ gesetzt werden.\n",
    "\n",
    "**Tipp:** Benutzen Sie für die Zerlegung des Strings und für die Darstellung aller Wörter mit ausschließlich kleinen Buchstaben die Funktionen _split(), strip('sep')_ und _lower()_ der Klasse _String_.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Um ein gegebenes Dokument in seine Woerter zu zerlegen, wird sich einer Hilfsmethode der NLTK-Library bedient.\n",
    "Diese Library ist ein Werkzeugkasten fuer alle moeglichen NLP-Prozesse und Techniken.\n",
    "\n",
    "Die Methode *NLTK.word_tokenize* splittet das Dokument in seine Bestandteile anhand von vordefinierten Regeln.\n",
    "\n",
    "Um die enstandenen Woerter zu filtern kann man die gegebene *word_filter* Methode anpassen. In diesem Fall werden nur\n",
    "Woerter behalten, die ein Lange zwischen 2 und 20 Zeichen haben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import operator\n",
    "import os\n",
    "\n",
    "import nltk\n",
    "import spacy\n",
    "from pandas import DataFrame\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n",
    "def get_words(doc, filter_f=None):\n",
    "    words = nltk.word_tokenize(doc)\n",
    "\n",
    "    def word_filter(word):\n",
    "        return 3 <= len(word) < 21\n",
    "\n",
    "    words_filtered = [word for word in words if (word_filter(word) if filter_f is None else filter_f(word))]\n",
    "    return words_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die get_words Methode wurde auf eine Art und Weise implementiert, mit der später die word_filter Methode ersetzt werden kann, sollte man sich dafür entscheiden andere Wortlängen oder bestimmte andere Elemente zu filtern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Classifier\n",
    "\n",
    "**Aufgabe:**\n",
    "Implementieren Sie den Naive Bayes Classifier für die Dokumentklassifikation. Es bietet sich an die Funktionalität des Klassifikators und das vom Klassifikator gelernte Wissen in einer Instanz einer Klasse _Classifier_ zu kapseln. In diesem Fall kann wie folgt vorgegangen werden:\n",
    "\n",
    "* Im Konstruktor der Klasse wird je ein Dictionary für die Instanzvariablen _fc_ und _cc_ (siehe oben) initialisiert. Dabei ist _fc_ ein verschachteltes Dictionary. Seine Keys sind die bisher gelernten Worte, die Values sind wiederum Dictionaries, deren Keys die Kategorien _Good_ und _Bad_ sind und deren Values zählen wie häufig das Wort bisher in Dokumenten der jeweiligen Kategorie auftrat. Das Dictionary _cc_ hat als Keys die Kategorien _Good_ und _Bad_. Die Values zählen wie häufig Dokumente der jeweiligen Kategorien bisher auftraten.\n",
    "* Im Konstruktor wird ferner der Instanzvariablen _getfeatures_ die Funktion _getwords()_ übergeben. Die Funktion _getwords()_ wurde bereits zuvor ausserhalb der Klasse definiert. Sinn dieses Vorgehens ist, dass andere Varianten um Merkmale aus Dokumenten zu extrahieren denkbar sind. Diese Varianten könnten dann ähnlich wie die _getwords()_-Funktion ausserhalb der Klasse definiert und beim Anlegen eines _Classifier_-Objekts der Instanzvariablen _getfeatures_ übergeben werden.  \n",
    "* Der Methode _incf(self,f,cat)_ wird ein Wort _f_ und die zugehörige Kategorie _cat_ des Dokuments in welchem es auftrat übergeben. In der Methode wird der _fc_-Zähler angepasst.\n",
    "* Der Methode _incc(self,cat)_ wird die Kategorie _cat_ des gerade eingelesenen Dokuments übergeben. In der Methode wird der _cc_-Zähler angepasst.\n",
    "* Die Methode _fcount(self,f,cat)_ gibt die Häufigkeit des Worts _f_ in den Dokumenten der Kategorie _cat_ zurück.\n",
    "* Die Methode _catcount(self,cat)_ gibt die Anzahl der Dokumente in der Kategorie _cat_ zurück.\n",
    "* Die Methode _totalcount(self)_ gibt die Anzahl aller Dokumente zurück.\n",
    "* Der Methode _train(self,item,cat)_ wird ein neues Trainingselement, bestehend aus der Betreffzeile (_item_) und der entsprechenden Kategorisierung (_cat_) übergeben. Der String _item_ wird mit der Instanzmethode _getfeatures_ (Diese referenziert _getwords()_) in Worte zerlegt. Für jedes einzelne Wort wird dann _incf(self,f,cat)_ aufgerufen. Ausserdem wird für das neue Trainingsdokument die Methode _incc(self,cat)_ aufgerufen.\n",
    "* Die Methode _fprob(self,f,cat)_ berechnet die bedingte Wahrscheinlichkeit $P(f | cat)$ des Wortes _f_ in der Kategorie _cat_ entsprechend der oben angegebenen Formeln, indem sie den aktuellen Stand des Zählers _fc(f,cat)_ durch den aktuellen Stand des Zählers _cc(cat)_ teilt.   \n",
    "* Die Methode _fprob(self,f,cat)_ liefert evtl. ungewollt extreme Ergebnisse, wenn noch wenig Wörter im Klassifizierer verbucht sind. Kommt z.B. ein Wort erst einmal in den Trainingsdaten vor, so wird seine Auftrittswahrscheinlichkeit in der Kategorie in welcher es nicht vorkommt gleich 0 sein. Um extreme Wahrscheinlichkeitswerte im Fall noch selten vorkommender Werte zu vermeiden, soll zusätzlich zur Methode _fprob(self,f,cat)_ die Methode _weightedprob(self,f,cat)_ implementiert und angewandt werden. Der von ihr zurückgegebene Wahrscheinlichkeitswert könnte z.B. wie folgt berechnet werden:$$wprob=\\frac{initprob+count \\cdot fprob(self,f,cat)}{1+count},$$ wobei $initprob$ ein initialer Wahrscheinlichkeitswert (z.B. 0.5) ist, welcher zurückgegeben werden soll, wenn das Wort noch nicht in den Trainingsdaten aufgetaucht ist. Die Variable $count$ zählt wie oft das Wort $f$ bisher in den Trainingsdaten auftrat. Wie zu erkennen ist, nimmt der Einfluss der initialen Wahrscheinlichkeit ab, je häufiger das Wort in den Trainingsdaten auftrat.\n",
    "* Nach dem Training soll ein beliebiges neues Dokument (Text-String) eingegeben werden können. Für dieses soll mit der Methode _prob(self,item,cat)_ die a-posteriori-Wahrscheinlichkeit $P(cat|item)$ (Aufgrund der Vernachlässigung der Evidenz handelt es sich hierbei genaugenommen um das Produkt aus a-posteriori-Wahrscheinlichkeit und Evidenz), mit der das Dokument _item_ in die Kategorie _cat_ fällt berechnet werden. Innerhalb der Methode _prob(self,item,cat)_ soll zunächst die Methode _weightedprob(self,f,cat)_ für alle Wörter $f$ im Dokument _item_ aufgerufen werden. Die jeweiligen Rückgabewerte von _weightedprob(self,f,cat)_ werden multipliziert. Das Produkt der Rückgabewerte von _weightedprob(self,f,cat)_ über alle Wörter $f$ im Dokument muss schließlich noch mit der a-priori Wahrscheinlichkeit $P(G)$ bzw. $P(B)$ entsprechend der oben aufgeführten Formeln multipliziert werden. Das Resultat des Produkts wird an das aufrufende Programm zurück gegeben, die Evidenz wird also vernachlässigt (wie oben begründet).\n",
    "\n",
    "\n",
    "\n",
    "Ein Dokument _item_ wird schließlich der Kategorie _cat_ zugeteilt, für welche die Funktion _prob(self,item,cat)_ den höheren Wert zurück gibt. Da die Rückgabewerte in der Regel sehr klein sind, werden in der Regel folgende Werte angezeigt. Wenn mit $g$ der Rückgabewert von _prob(self,item,cat=G)_ und mit $b$ der Rückgabewert von _prob(self,item,cat=B)_ bezeichnet wird dann ist die Wahrscheinlichkeit, dass $item$ in die Kategorie $G$ fällt, gleich:\n",
    "$$\n",
    "\\frac{g}{g+b}\n",
    "$$\n",
    "und die Wahrscheinlichkeit, dass $item$ in die Kategorie $B$ fällt, gleich:\n",
    "$$\n",
    "\\frac{b}{g+b}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Aus verschiedenen Gründen wurde die Methode ohne eine Klassenstruktur initialisiert. Einer dieser Gründe war das bessere Verständnis und die subjektive Vorliebe der Durchführenden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_data():\n",
    "    fc = dict()\n",
    "    cc = dict()\n",
    "\n",
    "    return {\"fc\": fc, \"cc\": cc}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Funktion, die in der gegebenen Classifier-Datenstruktur die Feature-Counts der jeweilgigen Kategorie um 1 erhöht.\n",
    "Es kann auch eine Liste an Features anstatt eines einzelnen Feature mitgegeben werden, dann wird die Funktion rekursiv\n",
    "aufgerufen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def inc_f(data, f, cat):\n",
    "    def _incf(data, f_list, cat):\n",
    "        if len(f_list) == 0:\n",
    "            return data\n",
    "\n",
    "        f_list_temp = f_list.copy()\n",
    "        f = f_list_temp.pop()\n",
    "        fc = data[\"fc\"].copy()\n",
    "        if f in fc:\n",
    "            fc[f][cat] = fc[f].setdefault(cat, 0) + 1\n",
    "        else:\n",
    "            fc[f] = {cat: 1}\n",
    "        return _incf({\"fc\": fc, \"cc\": data[\"cc\"]}, f_list_temp, cat)\n",
    "\n",
    "    if isinstance(f, list) or isinstance(f, set):\n",
    "        return _incf(data, f, cat)\n",
    "    else:\n",
    "        return _incf(data, [f], cat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Funktion die den Feature-Counter fuer ein bestimmtes Feature und eine bestimme Kategorie ausgibt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def f_count(data, f, cat):\n",
    "    try:\n",
    "        return data[\"fc\"][f][cat]\n",
    "    except KeyError:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Funktion, die die absolute Anzahl and Dokumenten fuer ein bestimmtes Feature ausgibt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def f_total_count(data, f):\n",
    "    try:\n",
    "        return sum(data[\"fc\"][f].values())\n",
    "    except KeyError:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Um die Funktionalitaet der vorherigen Funktionen zu testen, wird ein Test-Datensatz erstellt und auf Korrektheit nach\n",
    "Bearbeitung ueberprueft."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = initialize_data()\n",
    "print(data)\n",
    "new_data = inc_f(data, \"word\", \"good\")\n",
    "print\n",
    "new_data = inc_f(new_data, \"word\", \"good\")\n",
    "new_data = inc_f(new_data, [\"word\", \"word2\"], \"bad\")\n",
    "print(new_data)\n",
    "assert f_count(new_data, \"word\", \"good\") == 2\n",
    "assert f_total_count(new_data, \"word\") == 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Funktion, die den Dokumenten-Zaehler fuer eine gegebene Kategorie um eins erhoeht.\n",
    "Hier kann ebenfalls auch eine Liste an Kategorien mitgegeben werden, sodass die Zaehler rekursiv erhoeht werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def inc_c(data, cat):\n",
    "    def _inc_c(data, cat_list):\n",
    "        if len(cat_list) == 0:\n",
    "            return data\n",
    "        cat_list_temp = cat_list.copy()\n",
    "\n",
    "        cat = cat_list_temp.pop()\n",
    "        cc = data[\"cc\"].copy()\n",
    "        cc[cat] = cc.setdefault(cat, 0) + 1\n",
    "        return _inc_c({\"fc\": data[\"fc\"], \"cc\": cc}, cat_list_temp)\n",
    "\n",
    "    if isinstance(cat, list):\n",
    "        return _inc_c(data, cat)\n",
    "    else:\n",
    "        return _inc_c(data, [cat])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Funktion die den aktuellen Dokument-Zaehlerstand fuer eine bestimmte Kategorie ausgibt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def cat_count(data, cat):\n",
    "    try:\n",
    "        return data[\"cc\"][cat]\n",
    "    except KeyError:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Funktion, die den aktuellen Dokument-Zaehlerstand ueber alle Kategorien ausgibt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def total_count(data):\n",
    "    try:\n",
    "        count = sum(data[\"cc\"].values())\n",
    "        return count\n",
    "    except KeyError:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Um die Funktionalitaet der vorherigen Funktionen zu testen, wird ein Test-Datensatz erstellt und auf Korrektheit nach\n",
    "Bearbeitung ueberprueft. inc_f wird für das wort in good 2 mal aufgerufen, um hochzuzählen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = initialize_data()\n",
    "print(data)\n",
    "new_data = inc_f(data, \"word\", \"good\")\n",
    "print(new_data)\n",
    "new_data = inc_f(new_data, \"word\", \"good\")\n",
    "print(new_data)\n",
    "new_data = inc_f(new_data, [\"word\", \"word2\"], \"bad\")\n",
    "print(new_data)\n",
    "assert f_count(new_data, \"word\", \"good\") == 2\n",
    "assert f_total_count(new_data, \"word\") == 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Funktion, mit der ein Classifier-Datensatz mit einem oder mehreren Eingabe-Dokumenten traininert wird. Es kann eine\n",
    "Feature-Funktion mitgegeben werden, in der die List an Features ermittelt wird. Dabei wird rekursiv vorgegangen. Dabei kann die get_words Methode ausgetauscht werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train(data, items, cat, feature_f=get_words):\n",
    "    def _train(data, items, cat, feature_f):\n",
    "\n",
    "        if len(items) == 0:\n",
    "            return data\n",
    "\n",
    "        items_temp = items.copy()\n",
    "        features = set(feature_f(items_temp.pop()))\n",
    "        new_data = {\"fc\": inc_f(data, features, cat)[\"fc\"], \"cc\": inc_c(data, cat)[\"cc\"]}\n",
    "        return _train(new_data, items_temp, cat, feature_f)\n",
    "\n",
    "    if isinstance(items, list) or isinstance(items, set):\n",
    "        return _train(data, items, cat, feature_f)\n",
    "    else:\n",
    "        return _train(data, [items], cat, feature_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die train Methode wird von der Methode recursive_train aufgerufen. Dabei kann die get_words Methode ausgetauscht werden. Ihr werden die entsprechenden Dokumente für die jeweilige Kategorie übergeben. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def recursive_train(data, documents_by_cat, feature_f=get_words):\n",
    "    if len(documents_by_cat) == 0:\n",
    "        return data\n",
    "    cat = list(documents_by_cat)[0]\n",
    "    new_data = train(data, documents_by_cat[cat], cat, feature_f)\n",
    "    new_documents_by_cat = documents_by_cat.copy()\n",
    "    new_documents_by_cat.pop(cat)\n",
    "    return recursive_train(new_data, new_documents_by_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Funktion, die die Wahrscheinlichkeit dafuer berechnet, dass ein Wort in einer bestimmten Kategorie auftritt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def f_prop(data, f, cat):\n",
    "    count_f = f_count(data, f, cat)\n",
    "    count_cat = cat_count(data, cat)\n",
    "    return count_f / count_cat if count_cat > 0 else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Da bei kleinen Traininsmengen die obrige Funktion unzuverlaessige Ergebnisse produziert, wird nun zusaetzlich eine\n",
    "Funktion implementiert, die dieses Problem umgeht. Hier wird eine initiale Wahrscheinlichkeit von $1 / len(classes)$\n",
    "genutzt, welche mit einem Gewicht multipliziert wird. Je mehr Woerter der Klassifier bereits\n",
    "gesehen hat, desto unwichtiger wird dieser \"Bias\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def weighted_prob(data, f, cat, init_prob_weight=1):\n",
    "    init_prob = 1 / len(data[\"cc\"])\n",
    "    count_f_total = f_total_count(data, f)\n",
    "    return ((init_prob_weight * init_prob) + (count_f_total * f_prop(data, f, cat))) / (\n",
    "            init_prob_weight + count_f_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Mit der folgenden Funktion wird die Wahrscheinlichkeit berechnet, dass eine gegebenes Dokument in eine gegebene Kategorie\n",
    "faellt. Hierbei kann wieder die Feature-Extraction Funktion beliebig ausgetauscht werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def prob(data, item, cat, feature_f=get_words):\n",
    "    features = feature_f(item)\n",
    "    weighted_probs = functools.reduce(operator.mul, [weighted_prob(data, f, cat) for f in features], 1)\n",
    "    return weighted_probs * (cat_count(data, cat) / total_count(data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Um jetzt die Klasse/Kategorie eines Items zu erkennen, wird eine Funktion implementiert, die ein trainierten Classifier-\n",
    "Datensatz und ein zu klassifizierendes Item nimmt und dabei die Klasse/Kategorie mit der hoechten Wahrscheinlichkeit\n",
    "zurueck gibt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def predict(data, item, feature_f=get_words):\n",
    "    classes = set(data[\"cc\"].keys())\n",
    "    class_probabilities = {c: prob(data, item, c, feature_f) for c in classes}\n",
    "    return list(classes)[list(class_probabilities.values()).index(max(class_probabilities.values()))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "\n",
    "**Aufgabe:**\n",
    "Instanzieren Sie ein Objekt der Klasse _Classifier_ und übergeben Sie der _train()_ Methode dieser Klasse mindestens 8 kategorisierte Dokumente (Betreffzeilen als Stringvariablen zusammen mit der Kategorie Good oder Bad). Definieren Sie dann ein beliebig neues Dokument und berechnen Sie für dieses die Kategorie, in welches es mit größter Wahrscheinlichkeit fällt. Benutzen Sie für den Test das in \n",
    "[NLP Vorlesung Document Classification](https://gitlab.mi.hdm-stuttgart.de/maucher/nlp/-/blob/master/Slides/03TextClassification.pdf)\n",
    "ausführlich beschriebene Beispiel zu implementieren. Berechnen Sie die Klassifikatorausgabe des Satzes _the money jumps_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Zuerst werden die Daten initialisiert. Ein Datum ist jeweils ein Tuple mit dem textuellen Inhalt sowie der Kategorie.\n",
    "Um das Training zu vereinfachen, werden die Trainingsdaten nach Kategorie aufgeteilt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "test_documents = [\n",
    "    (\"nobody owns the water\", \"good\"),\n",
    "    (\"the quick rabbit jumps fences\", \"good\"),\n",
    "    (\"buy pharmaceuticals now\", \"bad\"),\n",
    "    (\"make quick money at the online casino\", \"bad\"),\n",
    "    (\"the quick brown fox jumps\", \"good\"),\n",
    "    (\"next meeting is at night\", \"good\"),\n",
    "    (\"meeting with your superstar\", \"bad\"),\n",
    "    (\"money like water\", \"bad\")\n",
    "]\n",
    "test_documents_by_cat = {cat: [document_data[0] for document_data in test_documents if document_data[1] == cat]\n",
    "                         for cat in set([doc[1] for doc in test_documents])}\n",
    "print(test_documents_by_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Nun wird ein Classifier-Datensatz erzeugt und mit den, nach Kategorie getrennten, Trainings-Dokumenten traininert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = initialize_data()\n",
    "\n",
    "trained_data = recursive_train(data, test_documents_by_cat)\n",
    "DataFrame.from_dict(trained_data).tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Jetzt wird das Test-Item erstellt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_item = \"the money jumps\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Um den Algorithmus zu ueberpruefen, wid nun einmal die Häufigkeit des Auftretens der jeweiligen Wörter in den Dokumenten der Kategorien \"good\" und \"bad\" ausgegeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "trained_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun werden die Wahrscheinlichkeiten des Test Satzes für die beiden Kategorien ausgegeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "prob(trained_data, test_item, \"good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "prob(trained_data, test_item, \"bad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Gegeben dieser Wahrscheinlichkeiten wird nun die Klasse/Kategorie vorausgesagt, in welche das Test-Item mit der hoechten\n",
    "Wahrscheinlichkeit faellt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "predict(trained_data, test_item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Wie erwartet, und auch in den Vorlesungsfolien klar gemacht, faellt der Satz \"the money jumps\" in die Kategorie \"good\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Klassifikation von RSS Newsfeeds\n",
    "Mit dem unten gegebenen Skript werden Nachrichten verschiedener Newsserver geladen und als String abgespeichert.\n",
    "\n",
    "**Aufgaben:**\n",
    "1. Trainieren Sie Ihren Naive Bayes Classifier mit allen Nachrichten der in den Listen _trainTech_ und _trainNonTech_ definierten Servern. Weisen Sie für das Training allen Nachrichten aus _trainTech_ die Kategorie _Tech_ und allen Nachrichten aus _trainNonTech_ die Kategorie _NonTech_ zu.\n",
    "2. Nach dem Training sollen alle Nachrichten aus der Liste _test_ vom Naive Bayes Classifier automatisch klassifiziert werden. Gehen Sie davon aus, dass alle Nachrichten von [http://rss.golem.de/rss.php?r=sw&feed=RSS0.91](http://rss.golem.de/rss.php?r=sw&feed=RSS0.91) tatsächlich von der Kategorie _Tech_ sind und alle Nachrichten von den beiden anderen Servern in der Liste _test_ von der Kategorie _NonTech_ sind. Bestimmen Sie die _Konfusionsmatrix_ und die _Accuracy_ sowie für beide Klassen _Precision, Recall_ und _F1-Score_. Diese Qualitätsmetriken sind z.B. in [NLP Vorlesung Document Classification](https://gitlab.mi.hdm-stuttgart.de/maucher/nlp/-/blob/master/Slides/03TextClassification.pdf) definiert.\n",
    "3. Diskutieren Sie das Ergebnis\n",
    "4. Wie könnte die Klassifikationsgüte durch Modifikation der _getwords()_-Methode verbessert werden? Implementieren Sie diesen Ansatz und vergleichen Sie das Ergebnis mit dem des ersten Ansatzes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import feedparser\n",
    "\n",
    "\n",
    "def stripHTML(h):\n",
    "    p = ''\n",
    "    s = 0\n",
    "    for c in h:\n",
    "        if c == '<':\n",
    "            s = 1\n",
    "        elif c == '>':\n",
    "            s = 0\n",
    "            p += ' '\n",
    "        elif s == 0:\n",
    "            p += c\n",
    "    return p\n",
    "\n",
    "\n",
    "trainTech = ['http://rss.chip.de/c/573/f/7439/index.rss',\n",
    "             #'http://feeds.feedburner.com/netzwelt',\n",
    "             'http://rss1.t-online.de/c/11/53/06/84/11530684.xml',\n",
    "             'http://www.computerbild.de/rssfeed_2261.xml?node=13',\n",
    "             'http://www.heise.de/newsticker/heise-top-atom.xml']\n",
    "\n",
    "trainNonTech = ['http://newsfeed.zeit.de/index',\n",
    "                'http://newsfeed.zeit.de/wirtschaft/index',\n",
    "                'http://www.welt.de/politik/?service=Rss',\n",
    "                'http://www.spiegel.de/schlagzeilen/tops/index.rss',\n",
    "                'http://www.sueddeutsche.de/app/service/rss/alles/rss.xml',\n",
    "                'http://www.faz.net/rss/aktuell/'\n",
    "                ]\n",
    "test = [\"http://rss.golem.de/rss.php?r=sw&feed=RSS0.91\",\n",
    "        'http://newsfeed.zeit.de/politik/index',\n",
    "        'http://www.welt.de/?service=Rss'\n",
    "        ]\n",
    "\n",
    "# countnews = {}\n",
    "# countnews['tech'] = 0\n",
    "# countnews['nontech'] = 0\n",
    "# countnews['test'] = 0\n",
    "# print(\"--------------------News from trainTech------------------------\")\n",
    "# for feed in trainTech:\n",
    "#     print(\"*\" * 30)\n",
    "#     print(feed)\n",
    "#     f = feedparser.parse(feed)\n",
    "#     for e in f.entries:\n",
    "#         try:\n",
    "#             print('\\n---------------------------')\n",
    "#             fulltext = stripHTML(e.title + ' ' + e.description)\n",
    "#             print(fulltext)\n",
    "#             countnews['tech'] += 1\n",
    "#         except Exception as e:\n",
    "#             print(e)\n",
    "# print(\"----------------------------------------------------------------\")\n",
    "# print(\"----------------------------------------------------------------\")\n",
    "# print(\"----------------------------------------------------------------\")\n",
    "#\n",
    "# print(\"--------------------News from trainNonTech------------------------\")\n",
    "# for feed in trainNonTech:\n",
    "#     print(\"*\" * 30)\n",
    "#     print(feed)\n",
    "#     f = feedparser.parse(feed)\n",
    "#     for e in f.entries:\n",
    "#         try:\n",
    "#             print('\\n---------------------------')\n",
    "#             fulltext = stripHTML(e.title + ' ' + e.description)\n",
    "#             print(fulltext)\n",
    "#             countnews['nontech'] += 1\n",
    "#         except Exception as e:\n",
    "#             print(e)\n",
    "# print(\"----------------------------------------------------------------\")\n",
    "# print(\"----------------------------------------------------------------\")\n",
    "# print(\"----------------------------------------------------------------\")\n",
    "#\n",
    "# print(\"--------------------News from test------------------------\")\n",
    "# for feed in test:\n",
    "#     print(\"*\" * 30)\n",
    "#     print(feed)\n",
    "#     f = feedparser.parse(feed)\n",
    "#     for e in f.entries:\n",
    "#         try:\n",
    "#             print('\\n---------------------------')\n",
    "#             fulltext = stripHTML(e.title + ' ' + e.description)\n",
    "#             print(fulltext)\n",
    "#             countnews['test'] += 1\n",
    "#         except Exception as e:\n",
    "#             print(e)\n",
    "# print(\"----------------------------------------------------------------\")\n",
    "# print(\"----------------------------------------------------------------\")\n",
    "# print(\"----------------------------------------------------------------\")\n",
    "#\n",
    "# print('Number of used trainings samples in categorie tech', countnews['tech'])\n",
    "# print('Number of used trainings samples in categorie notech', countnews['nontech'])\n",
    "# print('Number of used test samples', countnews['test'])\n",
    "# print('--' * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Um an den Inahlt der Feeds zu kommen, wird erst einmal eine Funktion definiert, welche eine Liste\n",
    "von Servern crawlt, und die Inhalte der Feeds in einer Liste zurueck gibt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def fetch_data_from_server_list(feed_list):\n",
    "    def get_feed_data(feed):\n",
    "\n",
    "        def get_entry(entry):\n",
    "            try:\n",
    "                return stripHTML(f\"{entry.title} {entry.description}\")\n",
    "            except:\n",
    "                return None\n",
    "\n",
    "        f = feedparser.parse(feed)\n",
    "        return [get_entry(entry) for entry in f.entries if get_entry(entry)]\n",
    "\n",
    "    return [entry for feed in feed_list for entry in get_feed_data(feed)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Nun wird ein neue Classifier mit den kategorisierten Daten der Server trainiert. Die verwendeten Kategorien sind \"tech\" und \"nontech\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fresh_data = initialize_data()\n",
    "training_data = {\"nontech\": fetch_data_from_server_list(trainNonTech), \"tech\": fetch_data_from_server_list(trainTech)}\n",
    "model = recursive_train(fresh_data, training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um einen kleinen Blick in die gelernten Daten zu bekommen, wird ein Teil des Modells ausgegeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "list(model[\"fc\"])[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Wie man erkennen kann, sind im Modell auch Kategorie-unspezifische Woerter wie \"Das\" oder \"fuer\" enthalten,\n",
    "welche erst einmal unaussagekraeftig bei der Klassifikation sind. Es kann zwar einen Zusammenhang zwischen der Anzahl\n",
    "dieser allgemeine Woerter und der Kategorie geben, allerdings muss dieser nicht zwangslaeufig ein kausaler Zusammenhang sein, sondern kann auch lediglich mit der Art und Weise zusammen haengen, wie ein solcher Artikel verfasst wurde, also welche sprachlichen Muster ein Autor im Vergleich zu einem anderen hat.\n",
    "\n",
    "Ein klarer Verbesserungspunkt waere hier, solche unaussagekraeftigen Woerter in der Klassifikation weniger zu gewichten.\n",
    "Ein Ansatz dafuer waere die *inversed document frequency*, also die Inverse der Frequenz von Woertern in einem Dokument.\n",
    "Woerter, die sehr oft in einem Dokument vorkommen, werden dabei weniger stark gewichtet, da man davon ausgehen kann, dass\n",
    "es sich dabei um genau solche unaussagekraeftigen \"Fuellworter\" handelt.\n",
    "\n",
    "Es wurde die Ueberlegung gemacht, solch einen Algorithmus zu implementieren, da er allerdings sehr grosse Aenderungen\n",
    "fuer den Classifier mit sich ziehen wuerde, wurde fuer das Erste davon abgesehen. Weitere Möglichkeiten wäre, die Mindestlänge für Wörter zu beschränken, wobei dabei auch relevante Wörter verloren gehen würde. Mögliche Verbesserungen werden in der letzten Teilaufgabe weitergehend evaluiert. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_tech = fetch_data_from_server_list([\"http://rss.golem.de/rss.php?r=sw&feed=RSS0.91\"])\n",
    "test_data_non_tech = fetch_data_from_server_list([\"http://newsfeed.zeit.de/politik/index\",\n",
    "                                                  \"http://www.welt.de/?service=Rss\"])\n",
    "test_data_non_tech[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Jetzt wird eine Funktion definiert, die die Bewertungsmasse fuer einen Classifier ausgibt. Es wird jeweils der eigentliche\n",
    "Wert mit dem vorhergesagten Wert verglichen und in ein Data-Dictionary hinzugefuegt, welche dann jeweils einen Zaehler\n",
    "fuer true_[class] und false_[class] enthaelt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_classification_labels(predictions, actual):\n",
    "    def _get_classification_labels(predictions, actual, data=None):\n",
    "\n",
    "        if data is None:\n",
    "            data = {}\n",
    "\n",
    "        if len(predictions) == 0:\n",
    "            return data\n",
    "\n",
    "        prediction = predictions[0]\n",
    "        if prediction == actual:\n",
    "            new_data = data.copy()\n",
    "            key_name = f\"true_{actual}\"\n",
    "            new_data[key_name] = new_data.setdefault(key_name, 0) + 1\n",
    "        elif prediction != actual:\n",
    "            new_data = data.copy()\n",
    "            key_name = f\"false_{actual}\"\n",
    "            new_data[key_name] = new_data.setdefault(key_name, 0) + 1\n",
    "\n",
    "        new_predictions = predictions[1:].copy()\n",
    "        return _get_classification_labels(new_predictions, actual, new_data)\n",
    "\n",
    "    if isinstance(predictions, list):\n",
    "        return _get_classification_labels(predictions, actual)\n",
    "    else:\n",
    "        return _get_classification_labels([predictions], actual)\n",
    "\n",
    "\n",
    "def get_classification_labels_recursively(predictions_dict, data=None):\n",
    "    if data is None:\n",
    "        data = dict()\n",
    "\n",
    "    if len(predictions_dict) == 0:\n",
    "        return data\n",
    "\n",
    "    actual = list(predictions_dict)[0]\n",
    "    new_data = data.copy()\n",
    "    new_data.update(get_classification_labels(predictions_dict[actual], actual))\n",
    "    new_predictions_dict = predictions_dict.copy()\n",
    "    new_predictions_dict.pop(actual)\n",
    "    return get_classification_labels_recursively(new_predictions_dict, new_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da es sich bei den non-tech Artikeln um 2 Feeds/Server handelt, sollte man vergleichen, ob es sich auch allgemein um\n",
    "aehnlich viele Artikel handelt, damit ein sinnvoller Vergleich moeglich ist.\n",
    "Um das sicher zu stellen, wird der Support der verschiedenen Kategorien verglichen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "num_tech = len(test_data_tech)\n",
    "num_non_tech = len(test_data_non_tech)\n",
    "f\"Support tech: {num_tech}, support non-tech: {num_non_tech}, percentage difference {round(abs(num_tech - num_non_tech) / max([num_tech, num_non_tech]), 2)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Da der Unterschied der Anzahl der Items in den verschiedenen Kategorien bei wenigen Prozent des maximalen Wertes liegt,\n",
    "kann man davon ausgehen, dass eine Interpretation der Vergleichswerte auch ausreichen Aussagekraft ueber mehr als nur die\n",
    "ausgewaehlten Testdaten hat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Jetzt werden die Kategorien fuer die jeweiligen Server-Feeds vorausgesagt und in eine Dictionary gespeichert. Zur Veranschaulichung werden die Ergebnisse bereits geplottet, für Diskussion, siehe Confusion Matrix und Classification Report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "predictions = {\"tech\": [predict(model, item) for item in test_data_tech],\n",
    "               \"nontech\": [predict(model, item) for item in test_data_non_tech]}\n",
    "\n",
    "DataFrame(predictions[\"tech\"], columns=['Predicted category for tech']).value_counts().plot(kind=\"barh\", figsize=(7, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "DataFrame(predictions[\"nontech\"], columns=['Predicted category for non-tech']).value_counts().plot(kind=\"barh\", figsize=(7, 4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Um sich die Bewertungsmasse anzuschauen, werden diese nun ueber die vorausgesagten Kategorien gebildet und ausgegeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "get_classification_labels_recursively(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Da im Nachhinein aufgefallen ist, dass die *sklearn*-Bibliothek bereits eine Funktionalitaet besizt, welche diese\n",
    "Bewertungsmasse automatisch berechnet, wird diese nun auch noch einmal getestet, um sie mit den Werten der eigenen\n",
    "Funktion zu vergleichen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_true = [label_true for label_true in predictions for _ in range(len(predictions[label_true]))]\n",
    "y_pred = [label_pred for label_pred_list in predictions.values() for label_pred in label_pred_list]\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model[\"cc\"].keys())\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Wie man erkennen kann, sind die Werte gleich, koennen allerdings mit *sklear* etwas anschaulicher dargestellt werden. Es lässt sich erkennen, dass ein großteil der Werte richtig eingestuft wurde, es jedoch einige Abweichungen gibt. \n",
    "\n",
    "Um nun die verschiedenen Performance-Metriken, wie Precision, Recall und F1-Score zu interpretieren, wird\n",
    "zuerst einmal eine Classification-Report erstellt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "report = classification_report(y_true, y_pred, labels=list(model[\"cc\"].keys()))\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Im Allgemeinen sind die Scores, gegeben der kleinen Trainingsdaten, welche wiederum jeweils nur relativ wenig\n",
    "textuellen Inhalt zum trainieren enthalten, relativ hoch. Eine Wahrscheinlichkeit, dass ein non-tech Artikel auch als\n",
    "solcher erkannt wird liegt zum Zeitpunkt des Schreibens mit den gegebenen Artikeln bei 73% (recall Wert). Man sollte dazu erwaehnen,\n",
    "dass sich die Anzahl der Artikel und die Atikel selbst stuendlich aendern, und es durchaus der Fall sein kann,\n",
    "dass sich die Ergebnisse nach dem Verfassen dieser Diskussion noch einmal geringfuegig aendern.\n",
    "\n",
    "Die non-Tech Scores sind im Vergleich zu den Tech-Scores etwas hoeher. Dies kann auf die geringfuegig hoeher Anzahl an\n",
    "Trainingsdokumenten zurueckzufuehren sein.\n",
    "Wie gut erkennbar ist, ist der Recall bei non-Tech leicht groesser als die Precision, was bedeutet, dass es dort im Vergleich\n",
    "mehr falsch Positive gibt, als falsch Negative. Dies koennte daran liegen, dass non-Tech Beitraege in der\n",
    "Regel allgemeiner im Inhalt sind, also einen viel groesseren Themenraum, sowie Vokabelraum, abdecken.\n",
    "In diesem Themenraum kann es durchaus zu Ueberschneidungen kommen. Diese Ueberschneidungen koennen unabsichtlich durch\n",
    "eine tech-lastige Wortwahl entstehen, oder auch rein absichtlich, falls in so einem allgemeinen News-Feed ein Tech-Artikel hereinrutscht.\n",
    "\n",
    "Auf der anderen Seite zeigen die Tech-Predictions eine hoehere Precision im Vergleich zum Recall auf.\n",
    "Ergo, dass es vergleichsweise mehr false positives als false negatives gibt. Dies bedeutet, dass der Classifier eine\n",
    "bessere Genauigkeit im Erkennen von Tech-Artikeln aufweist, allerdings dadurch manch einen tech-Artikel nicht als solchen\n",
    "identifiziert.\n",
    "\n",
    "Um die Ergebnisse jetzt zu verbessern, koennte man den Classifier ueber die Zeit weitertrainieren. Somit wird er sich\n",
    "mehr und mehr an die zwei Klassen annaehern, und die Scores sollten sich immer weiter an die 1 annaehern.\n",
    "Da aber, wie immer, die Gefahr des overfittings besteht, sollte man dies nicht zu lange machen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Wie schon in der vorherigen Diskussion angesprochen, waere eine Moeglichkeit, die Ergebnisse des\n",
    "Classifiers zu verbessern, unaussagekraeftige Woerter herauszufiltern. Dazu gehoeren grammatische Fuellwoerter\n",
    "wie Artikel oder Praepositionen. Diese sind zwar bei einer Sentiment-Analysis von Wichtigkeit, koennen aber\n",
    "bei einer Dokumentklassifizierung vernachlaessigt werden, da es keinen kausalen Zusammenhang zwischen diesen\n",
    "Woertern und der Kategorie eines Dokumentes gibt. Wie schon erwaehnt, kann dies von anderen Faktoren,\n",
    "wie zum Beispiel dem Schreibstil des Autors des Artikels abhaengen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Da man aus Hauptwoertern, also Nomen, in der Regel, am meisten Informationen ueber ein Dokument\n",
    "bekommen kann, wird im Folgenden eine Funktion fuer die feature selection implementiert, die lediglich\n",
    "bestimme Wortgruppen auswaehlt. Dies kann genutzt werden, um bestimme, unaussagekraeftige Wortgruppen, wie\n",
    "Artikel, Praepositionen, oder verschiedenste Jektionen, herauszufiltern.\n",
    "\n",
    "Hierbei wird auf das sogenannte Part-Of-Speech-Tagging zurueckgegriffen. Um es einfach und verstaendlich zu halten,\n",
    "wird hier lediglich ein Unigram-Tagger verwendet, als es wird jeweils nur ein Wort ohne Konntext bewertet um den POS-Tag zu finden.\n",
    "Als Hilfsmittel wird sich der *spacy*-Bibliothek bedient, welche ein bereits trainierten POS-Tagger fuer die\n",
    "deutsche Sprache enthaelt.\n",
    "\n",
    "Da die initiale *get_words*-Funktion bereits modular gestaltet wurde, muss hierfuer lediglich die Filter-Funktion\n",
    "ausgetauscht werden. Diese Filter-Funktion wird im Folgenden definiert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Zuerst muss der deutsche Tagger fuer die *spacy*-Bibliothek heruntergeladen werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "os.system(\"python -m spacy download de_core_news_sm\")\n",
    "tagger = spacy.load(\"de_core_news_sm\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Jetz kann die Filter-Funktion mit dem POS-Tagger definiert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def filter_by_pos_tag(word, pos_tags=None):\n",
    "    if pos_tags is None:\n",
    "        pos_tags = [\"NOUN\"]\n",
    "    tagged_word = tagger(word)\n",
    "    return tagged_word[0].pos_ in pos_tags\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Nun wird das neue Modell mit den Trainings-Daten trainiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "feature_function = functools.partial(get_words, filter_f=filter_by_pos_tag)\n",
    "model_improved = recursive_train(fresh_data, training_data, feature_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Wenn man sich nun das Modell anschaut, kann man gut erkennen, dass es nur noch Nomen in\n",
    "der Feature-Count-Liste hat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "list(model_improved[\"fc\"])[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Jetzt wird das neue Modell genutzt um die Kategorien der noch ungesehenen Feeds vorauszusagen. Wichtig dabe ist,\n",
    "auch hier die neue Feature-Funktion anzugeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "predictions_new = {\"tech\": [predict(model_improved, item, feature_function) for item in test_data_tech],\n",
    "                   \"nontech\": [predict(model_improved, item, feature_function) for item in test_data_non_tech]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_true = [label_true for label_true in predictions_new for _ in range(len(predictions_new[label_true]))]\n",
    "y_pred = [label_pred for label_pred_list in predictions_new.values() for label_pred in label_pred_list]\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model[\"cc\"].keys())\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "report = classification_report(y_true, y_pred, labels=list(model[\"cc\"].keys()))\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Wie man gut erkennen kann, sind die Scores um einiges gestiegen. Precision bei nontech, sowie recall bei\n",
    "tech sind, zum Zeitpunkt des Schreibens bei 0.95. Die Unterschiede zwischen Precision und Recall bei den beiden\n",
    "Kategorien sind nach wie vor vorhanden, und sind somit wahrscheinlich, wie bereits beschrieben, nicht auf die Kategorien\n",
    "zurueckzufuehren.\n",
    "\n",
    "Die Verbesserung ist, wie erwartet, auf das Weglassen von unaussagekraeftigen Woertern zuruckzufuehren, welche den Classifier\n",
    "\"verwirren\" und somit die Entscheidung beeinflussen.\n",
    "\n",
    "Um die Scores weiter zu verbessern koennte man nun noch mehr Trainingsdokumente nutzen, um den Classifier zu trainieren.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Annhame: Nomen sind tendenziell immer relevant, aber lange Verben können auch relevant sein. \n",
    "Vorschlag wäre: Alle Nomen verwenden, und alle längeren anderen Wörter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_pos_tag_and_length(word, pos_tags=None):\n",
    "    if pos_tags is None:\n",
    "        pos_tags = [\"NOUN\"]\n",
    "    tagged_word = tagger(word)\n",
    "    if(5 <= len(word) <21):\n",
    "        return word\n",
    "    return tagged_word[0].pos_ in pos_tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_function = functools.partial(get_words, filter_f=filter_by_pos_tag_and_length)\n",
    "model_improved = recursive_train(fresh_data, training_data, feature_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(model_improved[\"fc\"])[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier kann man erkennen, das potentiell relevante Wörter weiterhin enthalten sind, die bei dem vorherigem Verfahren aussortiert wurden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_combined = {\"tech\": [predict(model_improved, item, feature_function) for item in test_data_tech],\n",
    "                   \"nontech\": [predict(model_improved, item, feature_function) for item in test_data_non_tech]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true= 0\n",
    "y_pred=0\n",
    "\n",
    "y_true = [label_true for label_true in predictions_combined for _ in range(len(predictions_new[label_true]))]\n",
    "y_pred = [label_pred for label_pred_list in predictions_combined.values() for label_pred in label_pred_list]\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model[\"cc\"].keys())\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(y_true, y_pred, labels=list(model[\"cc\"].keys()))\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie man sieht sind die Resultate hier deutlich schlechter als bei dem vorherigen Ergebnis, bei dem nur nach Nomen gefiltert wurden. Es scheint, als würden Wörter die keine Nomen sind auch bei einer höheren mindestlänge zu ungenaueren Vorraussagen führen. Des weiteren wird getestet, zu welchen Resultaten es führt, lediglich die Wortlänge zu beschränken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_length(word, pos_tags=None):\n",
    "    if pos_tags is None:\n",
    "        pos_tags = [\"NOUN\"]\n",
    "    tagged_word = tagger(word)\n",
    "    if(5 <= len(word) <21):\n",
    "        return word\n",
    "    return tagged_word[0].pos_ in pos_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_function = functools.partial(get_words, filter_f=filter_by_length)\n",
    "model_new = recursive_train(fresh_data, training_data, feature_function)\n",
    "predictions_combined = {\"tech\": [predict(model_new, item, feature_function) for item in test_data_tech],\n",
    "                   \"nontech\": [predict(model_new, item, feature_function) for item in test_data_non_tech]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true= 0\n",
    "y_pred=0\n",
    "\n",
    "y_true = [label_true for label_true in predictions_combined for _ in range(len(predictions_new[label_true]))]\n",
    "y_pred = [label_pred for label_pred_list in predictions_combined.values() for label_pred in label_pred_list]\n",
    "report = classification_report(y_true, y_pred, labels=list(model[\"cc\"].keys()))\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "nav_menu": {},
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}